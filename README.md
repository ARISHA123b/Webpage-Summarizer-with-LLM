# Webpage-Summarizer-with-LLM
his project scrapes a given website and parse the data , extracts relevant text, and summarizes it using a Large Language Model (LLM). It supports both Ollama (local models like gemma:2-27b or llama3.2) and OpenAI models (like gpt-4o-mini).

ğŸš€ Features
1.Web Scraping â€” Fetches HTML content and cleans it with BeautifulSoup
2.Custom Headers â€” Avoids blocking by sending browser-like headers
3.Text Parsing â€” Removes unnecessary elements like scripts, styles, images, and inputs
4.LLM Summarization â€” Sends extracted text to an LLM for a concise summary
5.Flexible Backends â€” Choose between local Ollama models or OpenAI API

ğŸ›  Requirements
Install dependencies:
pip install requests beautifulsoup4 python-dotenv openai
ğŸ“¦ Setup
1ï¸âƒ£ Using Ollama (Local)
Install Ollama from: https://ollama.com/download
Pull your desired model:
bash
ollama pull llama3.2
Start Ollama:
from openai import OpenAI
MODEL = "gemma:2-27b"
openai = OpenAI(base_url="http://localhost:11434/v1", api_key="ollama")

2ï¸âƒ£ Using OpenAI API
Create an .env file in the project root:
OPENAI_API_KEY=your_openai_api_key_here
from openai import OpenAI
MODEL = "gpt-4o-mini"
openai = OpenAI()
â–¶ï¸ Running the Script
Example:
from summarizer import display_summary
display_summary("https://example.com")
ğŸ§  How It Works
1.Website class â†’ Downloads and parses HTML
2.messages_for() â†’ Prepares the system and user prompts for the LLM
3.summarize() â†’ Sends extracted text to the model and gets a summary
4.display_summary() â†’ Displays the summary in Markdown format

ğŸ”„ Switching Between Ollama & OpenAI
For Ollama:
MODEL = "gemma:2-27b"
openai = OpenAI(base_url="http://localhost:11434/v1", api_key="ollama")
For OpenAI:
MODEL = "gpt-4o-mini"
openai = OpenAI()

text
Copy
Edit
$ python summarizer.py
Website: https://example.com
Summary: This summary is generated using OpenAIâ€™s GPT-4o-mini API, offering faster but cloud-based process
